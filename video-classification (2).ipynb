{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f15f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:15.604698Z",
     "iopub.status.busy": "2025-05-15T19:12:15.604400Z",
     "iopub.status.idle": "2025-05-15T19:12:37.344203Z",
     "shell.execute_reply": "2025-05-15T19:12:37.343270Z"
    },
    "papermill": {
     "duration": 21.746914,
     "end_time": "2025-05-15T19:12:37.346075",
     "exception": false,
     "start_time": "2025-05-15T19:12:15.599161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 19:12:20.086114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747336340.340696      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747336340.416504      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "   # STEP 1: IMPORTS AND SETUP\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (ConvLSTM2D, BatchNormalization, MaxPooling3D,\n",
    "                                     TimeDistributed, Dropout, Flatten, Dense, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327df184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:37.354625Z",
     "iopub.status.busy": "2025-05-15T19:12:37.354091Z",
     "iopub.status.idle": "2025-05-15T19:12:37.359334Z",
     "shell.execute_reply": "2025-05-15T19:12:37.358382Z"
    },
    "papermill": {
     "duration": 0.011548,
     "end_time": "2025-05-15T19:12:37.361189",
     "exception": false,
     "start_time": "2025-05-15T19:12:37.349641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2: PARAMETERS\n",
    "FRAME_HEIGHT = 112\n",
    "FRAME_WIDTH = 112\n",
    "SEQUENCE_LENGTH = 16\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47558360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:37.369038Z",
     "iopub.status.busy": "2025-05-15T19:12:37.368683Z",
     "iopub.status.idle": "2025-05-15T19:12:37.375819Z",
     "shell.execute_reply": "2025-05-15T19:12:37.374785Z"
    },
    "papermill": {
     "duration": 0.012963,
     "end_time": "2025-05-15T19:12:37.377461",
     "exception": false,
     "start_time": "2025-05-15T19:12:37.364498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3: FEATURE EXTRACTION\n",
    "\n",
    "def feature_extraction(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_interval = max(int(frame_count / SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    for counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, counter * skip_interval)\n",
    "        ret, frame = video_reader.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "        frame = frame.astype('float32') / 255.0\n",
    "        frames_list.append(frame)\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    while len(frames_list) < SEQUENCE_LENGTH:\n",
    "        frames_list.append(np.zeros((FRAME_HEIGHT, FRAME_WIDTH, 3)))\n",
    "\n",
    "    return np.array(frames_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0acf81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:37.385732Z",
     "iopub.status.busy": "2025-05-15T19:12:37.385246Z",
     "iopub.status.idle": "2025-05-15T19:12:37.394223Z",
     "shell.execute_reply": "2025-05-15T19:12:37.393251Z"
    },
    "papermill": {
     "duration": 0.014982,
     "end_time": "2025-05-15T19:12:37.396007",
     "exception": false,
     "start_time": "2025-05-15T19:12:37.381025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 4: LOAD DATA\n",
    "\n",
    "def load_video_data(paths, augment=False):\n",
    "    datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1,\n",
    "                                 height_shift_range=0.1, horizontal_flip=True, zoom_range=0.1)\n",
    "    features, labels = [], []\n",
    "    label_index = 0\n",
    "\n",
    "    for folder in paths:\n",
    "        video_files = [f for f in os.listdir(folder) if f.endswith('.avi')][:100]\n",
    "        for file in video_files:\n",
    "            video_path = os.path.join(folder, file)\n",
    "            frames = feature_extraction(video_path)\n",
    "            if augment:\n",
    "                frames = np.array([datagen.random_transform(f) for f in frames])\n",
    "            features.append(frames)\n",
    "            labels.append(label_index)\n",
    "        label_index += 1\n",
    "\n",
    "    return np.array(features, dtype='float32'), tf.keras.utils.to_categorical(np.array(labels), NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936fc7f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:37.403880Z",
     "iopub.status.busy": "2025-05-15T19:12:37.403521Z",
     "iopub.status.idle": "2025-05-15T19:12:37.432602Z",
     "shell.execute_reply": "2025-05-15T19:12:37.431659Z"
    },
    "papermill": {
     "duration": 0.03507,
     "end_time": "2025-05-15T19:12:37.434381",
     "exception": false,
     "start_time": "2025-05-15T19:12:37.399311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 5: PATHS AND LABELS\n",
    "class_labels = pd.read_csv(\"../input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/classInd.txt\", sep=' ', header=None)\n",
    "class_labels.columns = ['index', 'label']\n",
    "paths = [f\"../input/ucf101/UCF101/UCF-101/{label}/\" for label in class_labels.label.values[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7cb819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:12:37.443463Z",
     "iopub.status.busy": "2025-05-15T19:12:37.443139Z",
     "iopub.status.idle": "2025-05-15T19:16:11.789864Z",
     "shell.execute_reply": "2025-05-15T19:16:11.788951Z"
    },
    "papermill": {
     "duration": 214.352899,
     "end_time": "2025-05-15T19:16:11.791760",
     "exception": false,
     "start_time": "2025-05-15T19:12:37.438861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 6: LOAD DATA\n",
    "X, y = load_video_data(paths, augment=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ff7d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:16:11.800002Z",
     "iopub.status.busy": "2025-05-15T19:16:11.799502Z",
     "iopub.status.idle": "2025-05-15T19:16:11.806433Z",
     "shell.execute_reply": "2025-05-15T19:16:11.805609Z"
    },
    "papermill": {
     "duration": 0.012875,
     "end_time": "2025-05-15T19:16:11.808163",
     "exception": false,
     "start_time": "2025-05-15T19:16:11.795288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 7: CLASS WEIGHTING\n",
    "y_labels = np.argmax(y_train, axis=1)\n",
    "class_weights = dict(enumerate(compute_class_weight('balanced', classes=np.unique(y_labels), y=y_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5c951f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:16:11.816355Z",
     "iopub.status.busy": "2025-05-15T19:16:11.816040Z",
     "iopub.status.idle": "2025-05-15T19:16:15.027197Z",
     "shell.execute_reply": "2025-05-15T19:16:15.026260Z"
    },
    "papermill": {
     "duration": 3.217133,
     "end_time": "2025-05-15T19:16:15.028769",
     "exception": false,
     "start_time": "2025-05-15T19:16:11.811636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 19:16:11.832315: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: MODEL BUILDING\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(FRAME_HEIGHT, FRAME_WIDTH, 3))\n",
    "    feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer(\"block4a_expand_activation\").output)\n",
    "\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        TimeDistributed(feature_extractor),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "\n",
    "        ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling3D(pool_size=(1, 2, 2)),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        ConvLSTM2D(filters=128, kernel_size=(3, 3), padding='same', return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "input_shape = (SEQUENCE_LENGTH, FRAME_HEIGHT, FRAME_WIDTH, 3)\n",
    "model = build_model(input_shape, NUM_CLASSES)\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ee83f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:16:15.038443Z",
     "iopub.status.busy": "2025-05-15T19:16:15.038158Z",
     "iopub.status.idle": "2025-05-15T19:16:15.043501Z",
     "shell.execute_reply": "2025-05-15T19:16:15.042243Z"
    },
    "papermill": {
     "duration": 0.011841,
     "end_time": "2025-05-15T19:16:15.045089",
     "exception": false,
     "start_time": "2025-05-15T19:16:15.033248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8454802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:16:15.055319Z",
     "iopub.status.busy": "2025-05-15T19:16:15.054942Z",
     "iopub.status.idle": "2025-05-15T20:08:47.718156Z",
     "shell.execute_reply": "2025-05-15T20:08:47.716950Z"
    },
    "papermill": {
     "duration": 3152.670234,
     "end_time": "2025-05-15T20:08:47.719766",
     "exception": false,
     "start_time": "2025-05-15T19:16:15.049532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 4s/step - accuracy: 0.3472 - loss: 2.1438 - val_accuracy: 0.6600 - val_loss: 1.1845 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.7438 - loss: 0.5924 - val_accuracy: 0.7800 - val_loss: 0.8167 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 4s/step - accuracy: 0.8645 - loss: 0.4224 - val_accuracy: 0.8600 - val_loss: 0.5292 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - accuracy: 0.8759 - loss: 0.2624 - val_accuracy: 0.9100 - val_loss: 0.3221 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - accuracy: 0.9442 - loss: 0.1557 - val_accuracy: 0.8900 - val_loss: 0.2500 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 4s/step - accuracy: 0.9714 - loss: 0.0668 - val_accuracy: 0.9000 - val_loss: 0.2345 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9384 - loss: 0.1208 - val_accuracy: 0.9000 - val_loss: 0.2389 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9933 - loss: 0.0352 - val_accuracy: 0.9100 - val_loss: 0.1861 - learning_rate: 1.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9872 - loss: 0.0519 - val_accuracy: 0.9400 - val_loss: 0.1925 - learning_rate: 1.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - accuracy: 0.9842 - loss: 0.0378 - val_accuracy: 0.9100 - val_loss: 0.1775 - learning_rate: 1.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - accuracy: 0.9894 - loss: 0.0311 - val_accuracy: 0.9400 - val_loss: 0.1334 - learning_rate: 1.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - accuracy: 0.9857 - loss: 0.0434 - val_accuracy: 0.9300 - val_loss: 0.1635 - learning_rate: 1.0000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - accuracy: 0.9961 - loss: 0.0140 - val_accuracy: 0.9300 - val_loss: 0.2018 - learning_rate: 1.0000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - accuracy: 0.9919 - loss: 0.0203 - val_accuracy: 0.9400 - val_loss: 0.1481 - learning_rate: 1.0000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - accuracy: 0.9958 - loss: 0.0108 - val_accuracy: 0.9600 - val_loss: 0.1363 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a8c603f9090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 9: TRAINING\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5),\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086ac9d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T20:08:47.806923Z",
     "iopub.status.busy": "2025-05-15T20:08:47.806598Z",
     "iopub.status.idle": "2025-05-15T20:09:02.802597Z",
     "shell.execute_reply": "2025-05-15T20:09:02.801434Z"
    },
    "papermill": {
     "duration": 15.041399,
     "end_time": "2025-05-15T20:09:02.804451",
     "exception": false,
     "start_time": "2025-05-15T20:08:47.763052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4s/step - accuracy: 0.9166 - loss: 0.1800\n",
      "Test Accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "# STEP 10: EVALUATION\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78adb759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T20:09:02.916100Z",
     "iopub.status.busy": "2025-05-15T20:09:02.915452Z",
     "iopub.status.idle": "2025-05-15T20:09:03.284524Z",
     "shell.execute_reply": "2025-05-15T20:09:03.283630Z"
    },
    "papermill": {
     "duration": 0.422485,
     "end_time": "2025-05-15T20:09:03.286427",
     "exception": false,
     "start_time": "2025-05-15T20:09:02.863942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 11: SAVE MODEL\n",
    "model.save(\"video_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63d0edf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T20:09:03.375120Z",
     "iopub.status.busy": "2025-05-15T20:09:03.374690Z",
     "iopub.status.idle": "2025-05-15T20:09:03.381447Z",
     "shell.execute_reply": "2025-05-15T20:09:03.380600Z"
    },
    "papermill": {
     "duration": 0.052422,
     "end_time": "2025-05-15T20:09:03.383060",
     "exception": false,
     "start_time": "2025-05-15T20:09:03.330638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 12: VIDEO PREDICTION FUNCTION\n",
    "def predict_video_class(video_path, model_path=\"video_classifier.h5\"):\n",
    "    model = load_model(model_path)\n",
    "    frames = feature_extraction(video_path)\n",
    "    input_frames = np.expand_dims(frames, axis=0)  # shape (1, 16, 112, 112, 3)\n",
    "    predictions = model.predict(input_frames)\n",
    "    predicted_index = np.argmax(predictions[0])\n",
    "    predicted_class = class_labels.label.values[30:][predicted_index]  # offset due to class slicing\n",
    "    confidence = predictions[0][predicted_index]\n",
    "    print(f\"Predicted Class: {predicted_class} ({confidence*100:.2f}%)\")\n",
    "    return predicted_class, confidence"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 841381,
     "sourceId": 1436057,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3417.992599,
   "end_time": "2025-05-15T20:09:07.648393",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-15T19:12:09.655794",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
